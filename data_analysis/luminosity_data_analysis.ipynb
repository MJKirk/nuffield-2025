{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminosity at the FCC-ee Collider - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps needed to make your comparison of Standard Model predictions to **simulated** data for Bhabha scattering are described in this notebook.\n",
    "\n",
    "The data we will examine come from a simulation of an experimental analysis for the process $e^+e^- \\rightarrow e^+ e^-$. We aim to study the distribution as a function of scattering angle:\n",
    "$$\\frac{\\mathrm{d}\\sigma}{\\mathrm{d}\\theta},$$\n",
    "which is measured in units of $\\mathrm{pb}$. This will plotted in bins of $\\theta$, measured in radians.\n",
    "\n",
    "In this notebook you will use small angle Bhabha scattering to determine the integrated luminosity of the FCC-ee, by comparing experimental data on the number of events, to a theoretical prediction for the cross-section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Structuring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information can be stored in many form on computing systems, **data** needs to be **structured** in sensible and comprehensible ways that simplify interaction and interpreting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful data structure in python (which exists in other programming languages) is the **array**, part of the `numpy` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are **containers** of variables which can be accessed individually, looped over, or altered by functions. Examples of how to use them are shown below - experiment with different values and functionalities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1: Simple array manipulations\n",
    "import numpy as np\n",
    "\n",
    "# Construct arrays of numbers\n",
    "array_1 = np.array([1,2,3,4])\n",
    "array_2 = np.array([5,6,7,8])\n",
    "\n",
    "print(\"Printing arrays\")\n",
    "print(array_1)\n",
    "print(array_2)\n",
    "\n",
    "# Operations for arrays\n",
    "print(\"\\nSimple array operations\")\n",
    "print(\"array_1 * array_2 = \", array_1 * array_2) # multiplies each element of array_1 by the corresponding element of array_2\n",
    "print(\"array_1 + array_2 = \", array_1 + array_2) # adds each element of array_1 to the corresponding element of array_2\n",
    "print(\"array_1 - array_2 = \", array_1 - array_2) # subtracts from each element of array_1 the corresponding element of array_2\n",
    "print(\"array_1 / array_2 = \", array_1 / array_2) # divides each element of array_1 by the corresponding element of array_2\n",
    "\n",
    "# Indexing for access to specific elements\n",
    "# The first element of the array is '0', the second is '1', ...\n",
    "print(\"\\nIndexing arrays\")\n",
    "print(\"array_1[0] = \", array_1[0])\n",
    "print(\"array_1[1] = \", array_1[1])\n",
    "print(\"array_1[2] = \", array_1[2])\n",
    "print(\"array_1[3] = \", array_1[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can also be **multi-dimensional**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 2: Multi-dimensional arrays\n",
    "import numpy as np\n",
    "\n",
    "multi_array_1 = np.array([[1,2],[3,4]]) # This forms a 2x2 matrix!\n",
    "multi_array_2 = np.array([[5,6],[7,8]])\n",
    "\n",
    "# The 'shape' function tells you the dimensions of the array\n",
    "print(\"Shape of multi_array_1 = \", np.shape(multi_array_1)) # 2x2 matrix\n",
    "print(\"Shape of multi_array_2 = \", np.shape(multi_array_2)) # 2x2 matrix\n",
    "\n",
    "# Multi-dimensional array operations:\n",
    "print(\"\\n\\nMulti-dimensional array operations\")\n",
    "print(\"multi_array_1 = \\n\", multi_array_1)\n",
    "print(\"multi_array_2 = \\n\", multi_array_2)\n",
    "print(\"multi_array_1 + multi_array_2 = \\n\", multi_array_1 + multi_array_2)\n",
    "\n",
    "# Indexing is more complicated:\n",
    "print(\"\\n\\nIndexing multi-dimensional arrays\")\n",
    "print(\"multi_array_1[0,0] = \", multi_array_1[0,0])\n",
    "print(\"multi_array_1[0,1] = \", multi_array_1[0,1])\n",
    "print(\"multi_array_1[1,0] = \", multi_array_1[1,0])\n",
    "print(\"multi_array_1[1,1] = \", multi_array_1[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access a whole row or column at the same time - this will come in useful later when plotting, as most `matplotlib` functions will accept an array to plot multiple data points all at once.\n",
    "You can also set whole columns at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We access an entire row or column by using a colon\n",
    "print(\"Accessing entire rows or columns\")\n",
    "print(\"multi_array_1[0,:] = \", multi_array_1[0,:]) # First row\n",
    "print(\"multi_array_1[:,0] = \", multi_array_1[:,0]) # First column\n",
    "\n",
    "multi_array_1[:,1] = np.array([9,10]) # We can set an entire column at once\n",
    "print(\"multi_array_1 after setting second column to [9,10]: \\n\", multi_array_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading external files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from experiments and from theoretical predictions are often stored in external files, which can be imported into arrays.\n",
    "\n",
    "We have provided data in the `.dat` files in the same folder as this notebook.\n",
    "The experimental data is provided as a list of data points in the following format:\n",
    "$$[\\mathtt{x\\_low \\quad x\\_high \\quad value \\quad error}],$$\n",
    "where $\\mathtt{x\\_low,\\ x\\_high}$ are the edges of the bins in $x$, $\\mathtt{value}$ is the value of the histogram at that point, and $\\mathtt{error}$ is the error of $y$.\n",
    "\n",
    "We can read these in python in a number of different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Native python open() function\n",
    "# 'r' argument means 'read-only'\n",
    "with open(\"small-angle-data.dat\", \"r\") as f:\n",
    "    print(f.read())\n",
    "    print(type(f.read()),\"\\n\\n\") # The native python 'open' function converts the file read to a string - not a useful format\n",
    "\n",
    "# Try with numpy - which has some smarter functions!\n",
    "experimental_data = np.genfromtxt(\"small-angle-data.dat\", dtype=float)\n",
    "print(experimental_data)\n",
    "print(type(experimental_data)) # The method has converted the data to a numpy array!\n",
    "print(np.shape(experimental_data)) # The dimensions are right too - 5 bins, 4 columns for each bin!\n",
    "\n",
    "# We can print all the measured values at once like we learned above\n",
    "print(experimental_data[:,2]) # Print third column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Exercise 5a: Making theoretical predictions\n",
    "\n",
    "Now we will calculate the theory prediction for the cross-section, as integrated over each the experimental angular bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a pre-written version of the Monte-Carlo functions you have previously written, and the SM cross-section function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def integrate_myfunction_a_b(n_points, my_function, a, b):\n",
    "    V = (b - a)\n",
    "    sum = 0\n",
    "    for i in range(n_points):\n",
    "        # Generate a random number between a and b\n",
    "        x = random.uniform(a, b)\n",
    "        # Calculate the value of the function at x\n",
    "        f_x = my_function(x)\n",
    "        # Add the value to the sum\n",
    "        sum += f_x\n",
    "    # Your code here\n",
    "    integral = (V * sum) / n_points\n",
    "    return integral\n",
    "\n",
    "def final_monte_carlo_function(my_function, a, b):\n",
    "    # Does Monte-Carlo integration of `my_function` over the interval [a, b] with 10,000 random samples,\n",
    "    # 10 times and returns the mean and standard deviation of the results.\n",
    "\n",
    "    values = [integrate_myfunction_a_b(10000, my_function, a, b) for _ in range(10)]\n",
    "    # Then calculate the mean and standard deviation of the results\n",
    "    mean = sum(values)/10 # Calculate the mean of the results\n",
    "    std_dev = (sum((x - mean)**2 for x in values) / 10)**0.5 # Calculate the standard deviation of the results\n",
    "    return (mean, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigma_dtheta_SM(theta, sqrt_s):\n",
    "    # Return the differential cross-section (in units of GeV^-2) for SM Bhabha scattering as a function of theta and sqrt_s (given in units of GeV)\n",
    "    MZ2 = 91.1876**2  # Z boson mass squared in GeV^2\n",
    "    Alfa = 1/128  # Fine-structure constant\n",
    "    sw = 0.231**0.5  # sine of the weak mixing angle\n",
    "    cw = (1 - sw**2)**0.5  # cosine of the weak mixing angle\n",
    "\n",
    "    cos = np.cos(theta)\n",
    "    S = sqrt_s**2  # Mandelstam variable S, which is the square of the centre-of-mass energy\n",
    "\n",
    "    return (Alfa**2*\n",
    "        (512*(MZ2 - S)**2*sw**4*(cw**2*(4*MZ2 + S - cos*S)- (-1 + cos)*S*sw**2)**2\n",
    "          + 2*(-1 + cos)**2*(1 + cos)**2*S**2*(-4*MZ2 + S + cos*S)**2*(cw**4 - 2*cw**2*sw**2 - 3*sw**4)**2\n",
    "          + ((-1 + cos)*cw**4*S*(-4*MZ2 + S + cos*S) + 2*cw**2*(16*MZ2**2 - 8*(1 + cos)*MZ2*S + (-5 + 4*cos + cos**2)*S**2)*sw**2 + (-1 + cos)*S*(-12*MZ2 + (9 + cos)*S)*sw**4)\n",
    "            * ((-1 + cos)*(1 + cos)**2*cw**4*S*(-4*MZ2 + S + cos*S)\n",
    "                + 2*cw**2*(16*(1 + 3*cos**2)*MZ2**2- 8*(1 + 3*cos + cos**2 + 3*cos**3)*MZ2*S + (-5 + 2*cos - 12*cos**2 + 14*cos**3 + cos**4)*S**2)*sw**2\n",
    "                + (-1 + cos)*S*(-4*(3 + 14*cos + 3*cos**2)*MZ2 + (9 + 3*cos + 27*cos**2 + cos**3)*S)*sw**4)\n",
    "          + ((-1 + cos)*cw**4*S*(-4*MZ2 + S + cos*S) - 2*cw**2*(cos**2*(8*MZ2 - 5*S)*S + S*(8*MZ2 + S) + 4*cos*(-4*MZ2**2 + S**2))*sw**2 + (-1 + cos)*S*(-28*MZ2 + S + 9*cos*S)*sw**4)\n",
    "            * ((-1 + cos)*(1 + cos)**2*cw**4*S*(-4*MZ2 + S + cos*S) - 2*cw**2*(cos**4*(8*MZ2 - 5*S)*S + 4*cos**2*(8*MZ2 - 3*S)*S + S*(8*MZ2 + S) + 2*cos**3*(-8*MZ2**2 + S**2) + cos*(-48*MZ2**2 + 16*MZ2*S + 14*S**2))*sw**2\n",
    "               + (-1 + cos)*S*(-4*(7 + 6*cos + 7*cos**2)*MZ2 + (1 + 27*cos + 3*cos**2 + 9*cos**3)*S)*sw**4)\n",
    "        )) / (1024.*(-1 + cos)**2*cw**4*(MZ2 - S)**2*S*(2*MZ2 + S - cos*S)**2*sw**4)\n",
    "\n",
    "def dsigma_dtheta_SM_240(theta):\n",
    "    # Return the differential cross-section (in units of GeV^-2) for SM Bhabha scattering at sqrt_s = 240 GeV\n",
    "    return dsigma_dtheta_SM(theta, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a 2 dimensional array, in the same format as the experimental data file we loaded, i.e.:\n",
    "$$[\\mathtt{x\\_low \\quad x\\_high \\quad value \\quad error}],$$\n",
    "but now with theoretical predictions, with errors from the Monte-Carlo function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_predictions = np.zeros_like(experimental_data) # Set up an empty array to hold the predictions, the same shape as the experimental data\n",
    "for i, row in enumerate(experimental_data):\n",
    "    theory_predictions[i, 0] = # The same as the experimental bin lower edge\n",
    "    theory_predictions[i, 1] = # The same as the experimental bin upper edge\n",
    "    theory_pred, theory_unc = # Use the Monte-Carlo function to calculate the theory prediction and uncertainty\n",
    "    # Then put these values into the third and fourth columns of the theory_predictions array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5b: Estimating the luminosity\n",
    "\n",
    "Now we have two sets of results, the experimental measurements of number of events, and theoretical predictions for the cross-section, we can compare them to estimate the luminosity of the data.\n",
    "We want to make a new 2 dimensional array, this time containing our estimate of the luminosity.\n",
    "\n",
    "**HINT**: Rearrange the formula $ N_\\mathrm{tot} = L_\\mathrm{int} \\times \\sigma $ to solve for the luminosity, and implement that formula in your code.\n",
    "\n",
    "**ASK US ABOUT**: how to work out the uncertainty on a ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your function from exercise 3d to make theoretical predictions for each of the experimental bins, as found in the data file loaded above.\n",
    "\n",
    "luminosity_estimates = np.zeros_like(experimental_data) # Set up an empty array to hold the luminosity estimates\n",
    "\n",
    "for i, row in enumerate(experimental_data):\n",
    "    # Extract the lower and upper limits of the bin from the array\n",
    "    lower_limit = # The same as the experimental bin lower edge\n",
    "    upper_limit = # The same as the experimental bin upper edge\n",
    "    luminosity = # Implement the formula for luminosity estimate\n",
    "    luminosity_error = # Implement the formula for luminosity error as we have discussed with you\n",
    "    luminosity_estimates[i] = [lower_limit, upper_limit, luminosity, luminosity_error]  # Store the results in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5c: Basic data processing\n",
    "\n",
    "For the purpose of plotting, we more often want data in the form\n",
    "$$ \\mathtt{x\\_centre} \\quad \\mathtt{bin\\_width} \\quad \\mathtt{value} \\quad \\mathtt{error} $$\n",
    "\n",
    "Write a function convert our array with the luminosity calculation to the format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_array(array):\n",
    "    # Write your code here\n",
    "    new_array = np.zeros_like(array) # Create a new array with the same shape as the input array\n",
    "    new_array[:, 0] = # What should go in this column?\n",
    "    new_array[:, 1] = # What should go in this column?\n",
    "    new_array[:, 2] = # What should go in this column?\n",
    "    new_array[:, 3] = # What should go in this column?\n",
    "\n",
    "print(convert_array(luminosity_estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5d: Producing the plot\n",
    "\n",
    "We will now plot our estimate of the integrated luminosity from each different bin of the data from `small-angle-data.dat`.\n",
    "\n",
    "Remember the guidance from the introduction of what goes into a good plot!\n",
    "\n",
    "You can use the previous variables and functions you have created/used earlier.\n",
    "\n",
    "Some useful links for matplotlib:\n",
    "- [Documentation for errorbar function](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
    "- [Example 1](https://matplotlib.org/stable/gallery/statistics/errorbar.html) and [Example 2](https://matplotlib.org/stable/gallery/statistics/errorbar_features.html) of using the errorbar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tell matplotlib to use LaTeX rendering, and a large font size\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif', size=18)\n",
    "\n",
    "# Plot the ratio of experimental data to theoretical prediction with errors using the plt.errorbar function\n",
    "converted_luminosity_estimate = convert_array(luminosity_estimates)\n",
    "# See how we can plot all the data at once\n",
    "plt.errorbar(converted_luminosity_estimate[0], converted_luminosity_estimate[1], yerr=converted_luminosity_estimate[3], xerr=converted_luminosity_estimate[1])\n",
    "\n",
    "\n",
    "# Add x and y axis labels\n",
    "\n",
    "# Now show the plot you have made\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it looks very consistent, average the five values to produce a combined luminosity value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean values of our luminosity estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuffield-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
